{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T12:14:22.295209Z",
     "start_time": "2019-01-04T12:14:22.287275Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二章 autograd 及Variable\n",
    "======================\n",
    "- **Autograd: 自动微分**<br>\n",
    "　　autograd包是PyTorch中神经网络的核心, 它可以为基于tensor的的所有操作提供自动微分的功能, 这是一个逐个运行的框架, 意味着反向传播是根据你的代码来运行的, 并且每一次的迭代运行都可能不同.\n",
    "- **Variable**<br>\n",
    "   tensor是硬币的话，那Variable就是钱包，它记录着里面的钱的多少，和钱的流向.\n",
    "   <img src=\"https://pic4.zhimg.com/80/v2-ab0e724afb75f6ba74ebb99f27e3a2b7_hd.jpg\">   　　　　　　　　variable是tensor的外包装，data属性存储着tensor数据，grad属性存储关于该变量的导数，creator是代表该变量的创造者.<br>\n",
    "   　　autograd.Variable 是包的中央类, 它包裹着Tensor, 支持几乎所有Tensor的操作,并附加额外的属性, 在进行操作以后, 通过调用.backward()来计算梯度, 通过.data来访问原始raw data (tensor), 并将变量梯度累加到.grad。<br>\n",
    "   　　Variable 与 Function互连并建立一个非循环图，编码完整的计算历史。 每个变量都有一个 .grad_fn 属性，它引用了一个已经创建了 Variable 的 操作,如加减乘除等（除了用户创建的变量代替creator is None 即第一个运算节点, .grad_fn为空)\n",
    "     <img src=\"https://pic2.zhimg.com/80/v2-0a938a33a77b14171cb17f2bbafc0ba1_hd.jpg\">\n",
    "   <a href=\"https://zhuanlan.zhihu.com/p/34298983\">==》参加链接</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:14:23.596195Z",
     "start_time": "2019-01-04T13:14:21.931420Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tensor是存在Variable中的.data里的，而cpu和gpu的数据是通过 .cpu()和.cuda()来转换的\n",
    "a=Variable(torch.Tensor([1]),requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:14:25.679842Z",
     "start_time": "2019-01-04T13:14:25.657686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:15:58.144760Z",
     "start_time": "2019-01-04T13:15:58.138002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:16:06.467078Z",
     "start_time": "2019-01-04T13:16:06.460116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:16:33.255240Z",
     "start_time": "2019-01-04T13:16:33.249020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:27:43.735829Z",
     "start_time": "2019-01-04T13:27:43.731592Z"
    }
   },
   "outputs": [],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动求导：\n",
    "对于中间变量，一旦它们完成了自身反传的使命，grad就会被释放掉。另外启始节点的grad_fn为空\n",
    "<img src=\"https://pic2.zhimg.com/80/v2-d6b51005dd1593a0541e3ca16e805809_hd.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:37:34.022884Z",
     "start_time": "2019-01-04T13:37:34.015321Z"
    }
   },
   "outputs": [],
   "source": [
    "a=Variable(torch.Tensor([1]),requires_grad=True) \n",
    "b=Variable(torch.Tensor([2]),requires_grad=True)\n",
    "c=Variable(torch.Tensor([3]),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:38:01.535365Z",
     "start_time": "2019-01-04T13:38:01.525484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([1.]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "d=a+b\n",
    "e=d+c\n",
    "e.backward()\n",
    "print(a.grad,b.grad,c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:38:20.752103Z",
     "start_time": "2019-01-04T13:38:20.748155Z"
    }
   },
   "outputs": [],
   "source": [
    "d.grad #中间梯度值不保存，为空"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:38:47.138062Z",
     "start_time": "2019-01-04T13:38:47.134092Z"
    }
   },
   "outputs": [],
   "source": [
    "a.grad_fn ##第一个节点的.grad_fn为空"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T13:38:53.316443Z",
     "start_time": "2019-01-04T13:38:53.310940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ThAddBackward at 0x7f9517f87908>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
